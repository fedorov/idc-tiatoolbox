{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c099ef",
   "metadata": {},
   "source": [
    "# Comparing TIAToolbox Nucleus Segmentation with IDC DICOM Segmentations\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fedorov/idc-tiatoolbox/blob/main/notebooks/08_comparing_with_idc_segmentations_copilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "IDC hosts nucleus segmentations stored as **DICOM Segmentation (SEG)** objects \u2014 binary pixel masks representing segmented nuclei on whole slide images. Unlike DICOM ANN (which stores point/polygon annotations), SEG objects contain actual pixel-level masks.\n",
    "\n",
    "In this notebook, we:\n",
    "1. Find a TCGA slide that has nucleus segmentations (DICOM SEG) in IDC\n",
    "2. Download both the slide and its segmentation\n",
    "3. Parse the DICOM SEG using `highdicom` to extract binary masks\n",
    "4. Run TIAToolbox's HoVer-Net on the same region\n",
    "5. Compare the two sets of results using pixel-level metrics (IoU, Dice)\n",
    "\n",
    "**GPU recommended** for HoVer-Net inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bb669",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Run the cell below to install dependencies. **On Colab, the runtime will automatically restart** after installation. After the restart, continue from the imports cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tiatoolbox idc-index openslide-bin \"numcodecs<0.16\" highdicom wsidicom shapely opencv-python\n",
    "\n",
    "# Restart runtime to pick up updated numpy (required on Colab)\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pydicom\n",
    "import highdicom as hd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from idc_index import IDCClient\n",
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "from tiatoolbox.models.engine.nucleus_instance_segmentor import NucleusInstanceSegmentor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    try:\n",
    "        torch.zeros(1, device=\"cuda\")\n",
    "    except RuntimeError:\n",
    "        print(\"CUDA available but not functional \u2014 falling back to CPU\")\n",
    "        device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cpu\":\n",
    "    print(\"Note: GPU is recommended. In Colab: Runtime > Change runtime type > T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a9cc3",
   "metadata": {},
   "source": [
    "## 1. Find a Slide with DICOM Segmentations\n",
    "\n",
    "DICOM Segmentations (SEG) on slide microscopy images are indexed in `seg_index`. We join with `index` to filter by source modality (SM) and find nucleus-related segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb219faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idc_client = IDCClient()\n",
    "idc_client.fetch_index(\"sm_index\")\n",
    "idc_client.fetch_index(\"seg_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find DICOM SEG series that segment slide microscopy images\n",
    "sm_segs = idc_client.sql_query(\"\"\"\n",
    "    SELECT\n",
    "        seg.SeriesInstanceUID as seg_series_uid,\n",
    "        seg.segmented_SeriesInstanceUID as slide_series_uid,\n",
    "        seg.AlgorithmName,\n",
    "        seg.total_segments,\n",
    "        i_seg.collection_id as seg_collection,\n",
    "        i_seg.analysis_result_id,\n",
    "        i_slide.collection_id as slide_collection,\n",
    "        i_slide.PatientID,\n",
    "        ROUND(i_slide.series_size_MB, 1) as slide_size_mb,\n",
    "        ROUND(i_seg.series_size_MB, 1) as seg_size_mb,\n",
    "        s.ObjectiveLensPower,\n",
    "        s.min_PixelSpacing_2sf as pixel_spacing_mm\n",
    "    FROM seg_index seg\n",
    "    JOIN index i_seg ON seg.SeriesInstanceUID = i_seg.SeriesInstanceUID\n",
    "    JOIN index i_slide ON seg.segmented_SeriesInstanceUID = i_slide.SeriesInstanceUID\n",
    "    JOIN sm_index s ON seg.segmented_SeriesInstanceUID = s.SeriesInstanceUID\n",
    "    WHERE i_slide.Modality = 'SM'\n",
    "        AND s.ObjectiveLensPower >= 20\n",
    "    ORDER BY i_slide.series_size_MB ASC\n",
    "    LIMIT 20\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Found {len(sm_segs)} slides with DICOM Segmentations\")\n",
    "sm_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b745b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available algorithms and analysis results\n",
    "print(\"Available segmentation sources:\")\n",
    "print(sm_segs[['AlgorithmName', 'analysis_result_id', 'slide_collection']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a slide - prefer smaller ones for faster demo\n",
    "# Filter for nucleus-related segmentations if possible\n",
    "nucleus_segs = sm_segs[\n",
    "    sm_segs['AlgorithmName'].str.lower().str.contains('nucle|hover|cell|instance', na=False) |\n",
    "    sm_segs['analysis_result_id'].str.lower().str.contains('nucle|seg', na=False)\n",
    "]\n",
    "\n",
    "if len(nucleus_segs) > 0:\n",
    "    selected = nucleus_segs.iloc[0]\n",
    "    print(\"Found nucleus-related segmentation\")\n",
    "else:\n",
    "    selected = sm_segs.iloc[0]\n",
    "    print(\"Using first available segmentation\")\n",
    "\n",
    "slide_series_uid = selected['slide_series_uid']\n",
    "seg_series_uid = selected['seg_series_uid']\n",
    "\n",
    "print(f\"\\nSelected slide:\")\n",
    "print(f\"  Patient: {selected['PatientID']}\")\n",
    "print(f\"  Collection: {selected['slide_collection']}\")\n",
    "print(f\"  Slide: {slide_series_uid} ({selected['slide_size_mb']} MB)\")\n",
    "print(f\"  SEG: {seg_series_uid} ({selected['seg_size_mb']} MB)\")\n",
    "print(f\"  Algorithm: {selected['AlgorithmName']}\")\n",
    "print(f\"  Segments: {selected['total_segments']}\")\n",
    "print(f\"  Objective: {selected['ObjectiveLensPower']}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d67ac4",
   "metadata": {},
   "source": [
    "## 2. Download the Slide and its Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ef40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = './slides'\n",
    "seg_dir = './segmentations'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "os.makedirs(seg_dir, exist_ok=True)\n",
    "\n",
    "# Download the slide\n",
    "idc_client.download_from_selection(\n",
    "    downloadDir=download_dir,\n",
    "    seriesInstanceUID=[slide_series_uid],\n",
    "    dirTemplate='%SeriesInstanceUID'\n",
    ")\n",
    "\n",
    "# Download the SEG object (flat, no directory template)\n",
    "idc_client.download_from_selection(\n",
    "    downloadDir=seg_dir,\n",
    "    seriesInstanceUID=[seg_series_uid],\n",
    "    dirTemplate=None\n",
    ")\n",
    "\n",
    "slide_path = os.path.join(download_dir, slide_series_uid)\n",
    "seg_files = [f for f in os.listdir(seg_dir) if f.endswith('.dcm')]\n",
    "print(f\"Downloaded slide: {slide_path}\")\n",
    "print(f\"Downloaded {len(seg_files)} SEG file(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83897a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open slide with TIAToolbox\n",
    "reader = WSIReader.open(slide_path)\n",
    "\n",
    "# DICOMWSIReader may not populate objective_power or mpp\n",
    "info = reader.info\n",
    "if info.objective_power is None:\n",
    "    info.objective_power = float(selected['ObjectiveLensPower'])\n",
    "if info.mpp is None:\n",
    "    pixel_spacing_um = float(selected['pixel_spacing_mm']) * 1000\n",
    "    info.mpp = np.array([pixel_spacing_um, pixel_spacing_um])\n",
    "\n",
    "print(f\"Slide: {type(reader).__name__}, dimensions: {info.slide_dimensions}\")\n",
    "print(f\"MPP: {info.mpp}\")\n",
    "\n",
    "thumbnail = reader.slide_thumbnail(resolution=1.25, units=\"power\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(thumbnail)\n",
    "plt.title(f\"Slide Thumbnail ({selected['PatientID']})\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97acd8a1",
   "metadata": {},
   "source": [
    "## 3. Parse IDC DICOM SEG\n",
    "\n",
    "DICOM Segmentation objects store binary pixel masks. We use `highdicom` to parse them and extract the segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SEG DICOM object\n",
    "seg_path = os.path.join(seg_dir, seg_files[0])\n",
    "seg_dcm = pydicom.dcmread(seg_path)\n",
    "\n",
    "print(f\"SEG SOP Class: {seg_dcm.SOPClassUID}\")\n",
    "print(f\"Rows: {seg_dcm.Rows}, Columns: {seg_dcm.Columns}\")\n",
    "print(f\"Number of Frames: {getattr(seg_dcm, 'NumberOfFrames', 1)}\")\n",
    "\n",
    "# List segments\n",
    "print(f\"\\nSegments:\")\n",
    "for i, segment in enumerate(seg_dcm.SegmentSequence):\n",
    "    print(f\"  {i+1}: {segment.SegmentLabel} (Algorithm: {getattr(segment, 'SegmentAlgorithmName', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7009932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use highdicom to read segmentation\n",
    "seg = hd.seg.segread(seg_path)\n",
    "\n",
    "print(f\"Segmentation type: {type(seg).__name__}\")\n",
    "print(f\"Number of segments: {len(seg.SegmentSequence)}\")\n",
    "\n",
    "# Get frame positions to understand spatial coverage\n",
    "if hasattr(seg, 'PerFrameFunctionalGroupsSequence'):\n",
    "    n_frames = len(seg.PerFrameFunctionalGroupsSequence)\n",
    "    print(f\"Number of frames: {n_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pixel data for the first segment\n",
    "# Note: SEG pixel data structure varies - it may be tiled or contain multiple frames\n",
    "try:\n",
    "    # Try highdicom's get_pixels_by_segment for single-frame or simple cases\n",
    "    seg_pixels = seg.get_pixels_by_segment(segment_numbers=[1])\n",
    "    print(f\"Extracted segmentation shape: {seg_pixels.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Using raw pixel array: {e}\")\n",
    "    # Fall back to raw pixel array\n",
    "    seg_pixels = seg.pixel_array\n",
    "    print(f\"Raw pixel array shape: {seg_pixels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb14a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spatial information from the SEG to understand coverage\n",
    "# Extract position of first frame\n",
    "if hasattr(seg, 'PerFrameFunctionalGroupsSequence') and len(seg.PerFrameFunctionalGroupsSequence) > 0:\n",
    "    first_frame = seg.PerFrameFunctionalGroupsSequence[0]\n",
    "    if hasattr(first_frame, 'PlanePositionSlideSequence'):\n",
    "        pos = first_frame.PlanePositionSlideSequence[0]\n",
    "        row_pos = float(pos.RowPositionInTotalPixelMatrix)\n",
    "        col_pos = float(pos.ColumnPositionInTotalPixelMatrix)\n",
    "        print(f\"First frame position: row={row_pos}, col={col_pos}\")\n",
    "    \n",
    "    # Get pixel spacing from SEG\n",
    "    if hasattr(first_frame, 'PixelMeasuresSequence'):\n",
    "        pm = first_frame.PixelMeasuresSequence[0]\n",
    "        seg_pixel_spacing = float(pm.PixelSpacing[0])\n",
    "        print(f\"SEG pixel spacing: {seg_pixel_spacing} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f439c",
   "metadata": {},
   "source": [
    "## 4. Extract Matching Region from Slide\n",
    "\n",
    "We need to extract the same region from the slide that the SEG covers. SEG frame positions tell us where each frame maps to in the source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pixel spacing from slide for coordinate conversion\n",
    "idc_client.fetch_index(\"sm_instance_index\")\n",
    "\n",
    "pixel_info = idc_client.sql_query(f\"\"\"\n",
    "    SELECT\n",
    "        TotalPixelMatrixColumns as width,\n",
    "        TotalPixelMatrixRows as height,\n",
    "        PixelSpacing_0 as pixel_spacing_mm\n",
    "    FROM sm_instance_index\n",
    "    WHERE SeriesInstanceUID = '{slide_series_uid}'\n",
    "    ORDER BY TotalPixelMatrixColumns DESC\n",
    "    LIMIT 1\n",
    "\"\"\")\n",
    "\n",
    "slide_px_spacing = pixel_info.iloc[0]['pixel_spacing_mm']\n",
    "slide_width = int(pixel_info.iloc[0]['width'])\n",
    "slide_height = int(pixel_info.iloc[0]['height'])\n",
    "print(f\"Slide pixel spacing: {slide_px_spacing:.6f} mm\")\n",
    "print(f\"Full resolution dimensions: {slide_width} x {slide_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine region covered by SEG\n",
    "# For multi-frame SEG, calculate bounding box of all frames\n",
    "if hasattr(seg, 'PerFrameFunctionalGroupsSequence'):\n",
    "    rows_list = []\n",
    "    cols_list = []\n",
    "    for frame in seg.PerFrameFunctionalGroupsSequence:\n",
    "        if hasattr(frame, 'PlanePositionSlideSequence'):\n",
    "            pos = frame.PlanePositionSlideSequence[0]\n",
    "            rows_list.append(float(pos.RowPositionInTotalPixelMatrix))\n",
    "            cols_list.append(float(pos.ColumnPositionInTotalPixelMatrix))\n",
    "    \n",
    "    if rows_list:\n",
    "        min_row, max_row = min(rows_list), max(rows_list)\n",
    "        min_col, max_col = min(cols_list), max(cols_list)\n",
    "        # Add frame dimensions\n",
    "        seg_rows = seg.Rows\n",
    "        seg_cols = seg.Columns\n",
    "        \n",
    "        # Bounds in slide pixel coordinates\n",
    "        bounds_x = int(min_col) - 1  # DICOM uses 1-based indexing\n",
    "        bounds_y = int(min_row) - 1\n",
    "        bounds_w = int(max_col - min_col) + seg_cols\n",
    "        bounds_h = int(max_row - min_row) + seg_rows\n",
    "        \n",
    "        print(f\"SEG coverage: ({bounds_x}, {bounds_y}) to ({bounds_x + bounds_w}, {bounds_y + bounds_h})\")\n",
    "        print(f\"Coverage size: {bounds_w} x {bounds_h} pixels\")\n",
    "else:\n",
    "    # Single frame - use full SEG dimensions\n",
    "    bounds_x, bounds_y = 0, 0\n",
    "    bounds_w, bounds_h = seg.Columns, seg.Rows\n",
    "    print(f\"Single frame SEG: {bounds_w} x {bounds_h} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea29f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If coverage is too large, select a smaller region for comparison\n",
    "max_tile_size = 2048\n",
    "\n",
    "if bounds_w > max_tile_size or bounds_h > max_tile_size:\n",
    "    # Center crop to max_tile_size\n",
    "    center_x = bounds_x + bounds_w // 2\n",
    "    center_y = bounds_y + bounds_h // 2\n",
    "    \n",
    "    tile_bounds = (\n",
    "        max(0, center_x - max_tile_size // 2),\n",
    "        max(0, center_y - max_tile_size // 2),\n",
    "        min(slide_width, center_x + max_tile_size // 2),\n",
    "        min(slide_height, center_y + max_tile_size // 2),\n",
    "    )\n",
    "    print(f\"Cropping to {max_tile_size}x{max_tile_size} region\")\n",
    "else:\n",
    "    tile_bounds = (\n",
    "        max(0, bounds_x),\n",
    "        max(0, bounds_y),\n",
    "        min(slide_width, bounds_x + bounds_w),\n",
    "        min(slide_height, bounds_y + bounds_h),\n",
    "    )\n",
    "\n",
    "print(f\"Tile bounds: {tile_bounds}\")\n",
    "tile_w = tile_bounds[2] - tile_bounds[0]\n",
    "tile_h = tile_bounds[3] - tile_bounds[1]\n",
    "print(f\"Tile size: {tile_w} x {tile_h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b76f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tile from slide\n",
    "# Read at native resolution to avoid DICOMWSIReader coordinate issues\n",
    "tile = reader.read_bounds(\n",
    "    bounds=tile_bounds,\n",
    "    resolution=info.objective_power,\n",
    "    units=\"power\",\n",
    ")\n",
    "\n",
    "# Resize to expected size if needed\n",
    "if tile.shape[0] != tile_h or tile.shape[1] != tile_w:\n",
    "    tile = np.array(Image.fromarray(tile).resize((tile_w, tile_h), Image.LANCZOS))\n",
    "\n",
    "print(f\"Extracted tile shape: {tile.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(tile)\n",
    "plt.title(f\"Extracted Region ({tile_w}x{tile_h})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a05459",
   "metadata": {},
   "source": [
    "## 5. Reconstruct IDC Segmentation Mask for the Region\n",
    "\n",
    "We need to assemble the SEG frames that fall within our tile region into a single binary mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54894a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty mask for the tile region\n",
    "idc_mask = np.zeros((tile_h, tile_w), dtype=np.uint8)\n",
    "\n",
    "# Get frame data and positions\n",
    "if hasattr(seg, 'PerFrameFunctionalGroupsSequence'):\n",
    "    pixel_array = seg.pixel_array\n",
    "    \n",
    "    for i, frame in enumerate(seg.PerFrameFunctionalGroupsSequence):\n",
    "        if hasattr(frame, 'PlanePositionSlideSequence'):\n",
    "            pos = frame.PlanePositionSlideSequence[0]\n",
    "            frame_row = int(float(pos.RowPositionInTotalPixelMatrix)) - 1  # 1-based to 0-based\n",
    "            frame_col = int(float(pos.ColumnPositionInTotalPixelMatrix)) - 1\n",
    "            \n",
    "            # Check if frame overlaps with our tile\n",
    "            frame_right = frame_col + seg.Columns\n",
    "            frame_bottom = frame_row + seg.Rows\n",
    "            \n",
    "            if (frame_col < tile_bounds[2] and frame_right > tile_bounds[0] and\n",
    "                frame_row < tile_bounds[3] and frame_bottom > tile_bounds[1]):\n",
    "                \n",
    "                # Get frame data\n",
    "                if pixel_array.ndim == 2:\n",
    "                    frame_data = pixel_array if i == 0 else pixel_array\n",
    "                else:\n",
    "                    frame_data = pixel_array[i]\n",
    "                \n",
    "                # Calculate overlap region\n",
    "                src_x1 = max(0, tile_bounds[0] - frame_col)\n",
    "                src_y1 = max(0, tile_bounds[1] - frame_row)\n",
    "                src_x2 = min(seg.Columns, tile_bounds[2] - frame_col)\n",
    "                src_y2 = min(seg.Rows, tile_bounds[3] - frame_row)\n",
    "                \n",
    "                dst_x1 = max(0, frame_col - tile_bounds[0])\n",
    "                dst_y1 = max(0, frame_row - tile_bounds[1])\n",
    "                dst_x2 = dst_x1 + (src_x2 - src_x1)\n",
    "                dst_y2 = dst_y1 + (src_y2 - src_y1)\n",
    "                \n",
    "                # Copy frame data to mask\n",
    "                idc_mask[dst_y1:dst_y2, dst_x1:dst_x2] = np.maximum(\n",
    "                    idc_mask[dst_y1:dst_y2, dst_x1:dst_x2],\n",
    "                    frame_data[src_y1:src_y2, src_x1:src_x2]\n",
    "                )\n",
    "else:\n",
    "    # Single frame case\n",
    "    idc_mask = seg.pixel_array.astype(np.uint8)\n",
    "\n",
    "print(f\"IDC mask shape: {idc_mask.shape}\")\n",
    "print(f\"IDC mask coverage: {np.sum(idc_mask > 0)} pixels ({100*np.sum(idc_mask > 0)/(tile_w*tile_h):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize IDC segmentation mask\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(tile)\n",
    "axes[0].set_title(\"Original Tile\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(idc_mask, cmap='gray')\n",
    "axes[1].set_title(\"IDC Segmentation Mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "overlay = tile.copy()\n",
    "overlay[idc_mask > 0] = [255, 0, 255]  # Magenta overlay\n",
    "axes[2].imshow(overlay)\n",
    "axes[2].set_title(\"IDC Segmentation Overlay\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4b96b",
   "metadata": {},
   "source": [
    "## 6. Run TIAToolbox HoVer-Net on the Same Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec86da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tile for HoVer-Net\n",
    "tile_path = './tile_for_seg_comparison.png'\n",
    "Image.fromarray(tile).save(tile_path)\n",
    "\n",
    "# Run HoVer-Net\n",
    "segmentor = NucleusInstanceSegmentor(\n",
    "    pretrained_model=\"hovernet_fast-pannuke\",\n",
    "    num_loader_workers=0,\n",
    "    num_postproc_workers=0,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "output = segmentor.predict(\n",
    "    imgs=[tile_path],\n",
    "    mode=\"tile\",\n",
    "    save_dir=\"./seg_comparison_results/\",\n",
    "    resolution=1.0,\n",
    "    units=\"baseline\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"HoVer-Net inference complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HoVer-Net results\n",
    "hovernet_nuclei = joblib.load(output[0][1] + '.dat')\n",
    "\n",
    "print(f\"TIAToolbox HoVer-Net detected: {len(hovernet_nuclei)} nuclei\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3285ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HoVer-Net contours to binary mask\n",
    "hovernet_mask = np.zeros((tile_h, tile_w), dtype=np.uint8)\n",
    "\n",
    "for nuc_id, nuc_data in hovernet_nuclei.items():\n",
    "    contour = nuc_data['contour'].astype(np.int32)\n",
    "    cv2.fillPoly(hovernet_mask, [contour], 1)\n",
    "\n",
    "print(f\"HoVer-Net mask shape: {hovernet_mask.shape}\")\n",
    "print(f\"HoVer-Net mask coverage: {np.sum(hovernet_mask > 0)} pixels ({100*np.sum(hovernet_mask > 0)/(tile_w*tile_h):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a332093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize HoVer-Net segmentation mask\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(tile)\n",
    "axes[0].set_title(\"Original Tile\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(hovernet_mask, cmap='gray')\n",
    "axes[1].set_title(\"HoVer-Net Mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "overlay = tile.copy()\n",
    "overlay[hovernet_mask > 0] = [0, 255, 255]  # Cyan overlay\n",
    "axes[2].imshow(overlay)\n",
    "axes[2].set_title(\"HoVer-Net Overlay\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27c798",
   "metadata": {},
   "source": [
    "## 7. Binary Mask Comparison: IoU and Dice\n",
    "\n",
    "Now we compare the two binary masks using pixel-level metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebfe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure masks are binary\n",
    "idc_binary = (idc_mask > 0).astype(np.uint8)\n",
    "hovernet_binary = (hovernet_mask > 0).astype(np.uint8)\n",
    "\n",
    "# Compute metrics\n",
    "intersection = np.sum(idc_binary & hovernet_binary)\n",
    "union = np.sum(idc_binary | hovernet_binary)\n",
    "idc_sum = np.sum(idc_binary)\n",
    "hovernet_sum = np.sum(hovernet_binary)\n",
    "\n",
    "# IoU (Intersection over Union)\n",
    "iou = intersection / union if union > 0 else 0\n",
    "\n",
    "# Dice coefficient\n",
    "dice = 2 * intersection / (idc_sum + hovernet_sum) if (idc_sum + hovernet_sum) > 0 else 0\n",
    "\n",
    "print(\"Binary Mask Comparison Metrics\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"IDC mask pixels:      {idc_sum:,}\")\n",
    "print(f\"HoVer-Net mask pixels: {hovernet_sum:,}\")\n",
    "print(f\"Intersection:          {intersection:,}\")\n",
    "print(f\"Union:                 {union:,}\")\n",
    "print(f\"\")\n",
    "print(f\"IoU (Jaccard):         {iou:.4f}\")\n",
    "print(f\"Dice (F1):             {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "# True Positive (both agree) = green\n",
    "# False Positive (HoVer-Net only) = red\n",
    "# False Negative (IDC only) = blue\n",
    "\n",
    "tp = idc_binary & hovernet_binary\n",
    "fp = (~idc_binary.astype(bool)) & hovernet_binary.astype(bool)\n",
    "fn = idc_binary.astype(bool) & (~hovernet_binary.astype(bool))\n",
    "\n",
    "# Create color-coded overlay\n",
    "confusion_overlay = tile.copy().astype(np.float32)\n",
    "confusion_overlay[tp > 0] = [0, 255, 0]    # Green - agreement\n",
    "confusion_overlay[fp > 0] = [255, 0, 0]    # Red - HoVer-Net only\n",
    "confusion_overlay[fn > 0] = [0, 0, 255]    # Blue - IDC only\n",
    "confusion_overlay = confusion_overlay.astype(np.uint8)\n",
    "\n",
    "print(f\"True Positives (agreement):   {np.sum(tp):,} pixels\")\n",
    "print(f\"False Positives (TIA only):   {np.sum(fp):,} pixels\")\n",
    "print(f\"False Negatives (IDC only):   {np.sum(fn):,} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "axes[0].imshow(tile)\n",
    "axes[0].set_title(\"Original Tile\", fontsize=13)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# IDC mask overlay\n",
    "idc_overlay = tile.copy()\n",
    "idc_overlay[idc_binary > 0] = [255, 0, 255]\n",
    "axes[1].imshow(idc_overlay)\n",
    "axes[1].set_title(f\"IDC SEG\\n({idc_sum:,} pixels)\", fontsize=13)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# HoVer-Net mask overlay\n",
    "hovernet_overlay = tile.copy()\n",
    "hovernet_overlay[hovernet_binary > 0] = [0, 255, 255]\n",
    "axes[2].imshow(hovernet_overlay)\n",
    "axes[2].set_title(f\"TIAToolbox HoVer-Net\\n({hovernet_sum:,} pixels)\", fontsize=13)\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Confusion overlay\n",
    "axes[3].imshow(confusion_overlay)\n",
    "axes[3].set_title(f\"Comparison (IoU={iou:.3f}, Dice={dice:.3f})\\nGreen=Both, Red=TIA only, Blue=IDC only\", fontsize=11)\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912e61f",
   "metadata": {},
   "source": [
    "### Zoomed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into a 512x512 region with nuclei\n",
    "zoom_size = 512\n",
    "\n",
    "# Find region with nuclei\n",
    "combined_mask = idc_binary | hovernet_binary\n",
    "if np.sum(combined_mask) > 0:\n",
    "    # Find centroid of nuclei\n",
    "    coords = np.argwhere(combined_mask)\n",
    "    center_y, center_x = coords.mean(axis=0).astype(int)\n",
    "else:\n",
    "    center_x, center_y = tile_w // 2, tile_h // 2\n",
    "\n",
    "zoom_x = max(0, min(tile_w - zoom_size, center_x - zoom_size // 2))\n",
    "zoom_y = max(0, min(tile_h - zoom_size, center_y - zoom_size // 2))\n",
    "\n",
    "# Extract zoomed regions\n",
    "zoomed_tile = tile[zoom_y:zoom_y+zoom_size, zoom_x:zoom_x+zoom_size]\n",
    "zoomed_confusion = confusion_overlay[zoom_y:zoom_y+zoom_size, zoom_x:zoom_x+zoom_size]\n",
    "zoomed_idc = idc_overlay[zoom_y:zoom_y+zoom_size, zoom_x:zoom_x+zoom_size]\n",
    "zoomed_hovernet = hovernet_overlay[zoom_y:zoom_y+zoom_size, zoom_x:zoom_x+zoom_size]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].imshow(zoomed_tile)\n",
    "axes[0].set_title(\"Original (zoomed)\", fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(zoomed_idc)\n",
    "axes[1].set_title(\"IDC SEG (zoomed)\", fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(zoomed_hovernet)\n",
    "axes[2].set_title(\"HoVer-Net (zoomed)\", fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(zoomed_confusion)\n",
    "axes[3].set_title(\"Comparison (zoomed)\", fontsize=12)\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c5347",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "\n",
    "- Use `seg_index` to find IDC's **DICOM Segmentation** objects on slide microscopy images\n",
    "- Download both the slide and its DICOM SEG\n",
    "- Parse DICOM SEG objects using `highdicom` to extract binary masks\n",
    "- Reconstruct segmentation masks from multi-frame DICOM SEG\n",
    "- Run TIAToolbox's **HoVer-Net** and convert instance contours to binary masks\n",
    "- **Compare using pixel-level metrics**: IoU (Jaccard Index) and Dice coefficient\n",
    "- **Visualize** agreement and disagreement with color-coded overlays\n",
    "\n",
    "**Key observations:**\n",
    "- IoU and Dice provide quantitative measures of segmentation overlap\n",
    "- Color-coded overlays show where methods agree (green), HoVer-Net-only detections (red), and IDC-only (blue)\n",
    "- Differences may arise from different algorithms, thresholds, or training data\n",
    "- Both approaches are complementary: IDC provides pre-computed segmentations, while TIAToolbox enables custom analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09385b",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "- **IDC:** Fedorov, A., et al. \"National Cancer Institute Imaging Data Commons: Toward Transparency, Reproducibility, and Scalability in Imaging Artificial Intelligence.\" *RadioGraphics* 43.12 (2023). https://doi.org/10.1148/rg.230180\n",
    "- **TIAToolbox:** Pocock, J., et al. \"TIAToolbox as an end-to-end library for advanced tissue image analytics.\" *Communications Medicine* 2, 120 (2022). https://doi.org/10.1038/s43856-022-00186-5\n",
    "- **HoVer-Net:** Graham, S., et al. \"Hover-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images.\" *Medical Image Analysis* 58 (2019). https://doi.org/10.1016/j.media.2019.101563\n",
    "- **highdicom:** Bridge, C., et al. \"Highdicom: A Python library for standardized encoding of image annotations and machine learning model outputs in pathology and radiology.\" *Journal of Digital Imaging* (2022). https://doi.org/10.1007/s10278-022-00683-y"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}