{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Tissue Patches from IDC Slides with TIAToolbox\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fedorov/idc-tiatoolbox/blob/main/notebooks/04_patch_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "TIAToolbox's `PatchPredictor` can classify tissue patches using pretrained deep learning models. In this notebook, we use the **ResNet18-Kather100K** model to classify tissue in a colorectal cancer slide from IDC into 9 tissue types:\n",
    "\n",
    "1. Adipose\n",
    "2. Background\n",
    "3. Debris\n",
    "4. Lymphocytes\n",
    "5. Mucus\n",
    "6. Smooth muscle\n",
    "7. Normal colon mucosa\n",
    "8. Cancer-associated stroma\n",
    "9. Colorectal adenocarcinoma epithelium\n",
    "\n",
    "**GPU recommended** for faster inference (but works on CPU too)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Installation\n\nRun the cell below to install dependencies. **On Colab, the runtime will automatically restart** after installation to pick up the updated numpy version. After the restart, continue from the imports cell below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%pip install tiatoolbox idc-index openslide-bin \"numcodecs<0.16\"\n\n# Restart runtime to pick up updated numpy (required on Colab)\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from idc_index import IDCClient\n",
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "from tiatoolbox.models.engine.patch_predictor import PatchPredictor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cpu\":\n",
    "    print(\"Note: GPU is recommended for faster inference.\")\n",
    "    print(\"In Colab: Runtime > Change runtime type > T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select and Download a Colorectal Cancer Slide\n",
    "\n",
    "The Kather100K model was trained on colorectal cancer tissue, so we'll use a slide from the `tcga_coad` (TCGA Colon Adenocarcinoma) collection for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idc_client = IDCClient()\n",
    "idc_client.fetch_index(\"sm_index\")\n",
    "\n",
    "candidates = idc_client.sql_query(\"\"\"\n",
    "    SELECT\n",
    "        i.SeriesInstanceUID,\n",
    "        i.PatientID,\n",
    "        i.collection_id,\n",
    "        ROUND(i.series_size_MB, 1) as size_mb,\n",
    "        s.ObjectiveLensPower,\n",
    "        s.max_TotalPixelMatrixColumns as width,\n",
    "        s.max_TotalPixelMatrixRows as height\n",
    "    FROM sm_index s\n",
    "    JOIN index i ON s.SeriesInstanceUID = i.SeriesInstanceUID\n",
    "    WHERE i.collection_id = 'tcga_coad'\n",
    "        AND s.ObjectiveLensPower >= 20\n",
    "    ORDER BY i.series_size_MB ASC\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "selected = candidates.iloc[0]\n",
    "series_uid = selected['SeriesInstanceUID']\n",
    "print(f\"Selected: {selected['PatientID']}, {selected['size_mb']} MB\")\n",
    "print(f\"  Dimensions: {selected['width']}x{selected['height']} @ {selected['ObjectiveLensPower']}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = './slides'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "idc_client.download_from_selection(\n",
    "    downloadDir=download_dir,\n",
    "    seriesInstanceUID=[series_uid],\n",
    "    dirTemplate='%SeriesInstanceUID'\n",
    ")\n",
    "\n",
    "slide_path = os.path.join(download_dir, series_uid)\n",
    "reader = WSIReader.open(slide_path)\n",
    "print(f\"Opened: {type(reader).__name__}, dimensions: {reader.info.slide_dimensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show slide thumbnail\n",
    "thumbnail = reader.slide_thumbnail(resolution=1.25, units=\"power\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(thumbnail)\n",
    "plt.title(f\"Slide Thumbnail ({selected['PatientID']})\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Patch Classification with PatchPredictor\n",
    "\n",
    "TIAToolbox's `PatchPredictor` supports three modes:\n",
    "- **`patch`**: Classify individual images/patches\n",
    "- **`tile`**: Classify a larger image tile\n",
    "- **`wsi`**: Classify an entire whole slide image with automatic patch extraction\n",
    "\n",
    "We'll use **WSI mode** which automatically extracts patches from tissue regions and classifies them.\n",
    "\n",
    "### About the Kather100K Model\n",
    "\n",
    "The `resnet18-kather100k` model is a ResNet-18 architecture trained on the [NCT-CRC-HE-100K dataset](https://zenodo.org/record/1214456) for 9-class tissue type classification in colorectal cancer histology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PatchPredictor with pretrained model\n",
    "predictor = PatchPredictor(\n",
    "    pretrained_model=\"resnet18-kather100k\",\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "print(f\"Model: resnet18-kather100k\")\n",
    "print(f\"Classes: {predictor.labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction in WSI mode\n",
    "# This will automatically extract patches from tissue regions and classify them\n",
    "output = predictor.predict(\n",
    "    imgs=[slide_path],\n",
    "    mode=\"wsi\",\n",
    "    save_dir=\"./patch_pred_results/\",\n",
    "    patch_input_shape=(224, 224),\n",
    "    stride_shape=(224, 224),\n",
    "    resolution=0.5,\n",
    "    units=\"mpp\",\n",
    "    on_gpu=(device == \"cuda\"),\n",
    ")\n",
    "\n",
    "print(f\"Prediction complete!\")\n",
    "print(f\"Number of patches classified: {len(output[0]['predictions'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Classification Results\n",
    "\n",
    "Let's create a tissue classification heatmap showing what type of tissue is present at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions and coordinates\n",
    "predictions = output[0]['predictions']\n",
    "coordinates = output[0]['coordinates']\n",
    "\n",
    "# Kather100K class names and colors\n",
    "class_names = predictor.labels\n",
    "class_colors = {\n",
    "    'ADI': [0.9, 0.8, 0.2],   # Adipose - yellow\n",
    "    'BACK': [0.9, 0.9, 0.9],  # Background - light gray\n",
    "    'DEB': [0.5, 0.3, 0.1],   # Debris - brown\n",
    "    'LYM': [0.2, 0.6, 0.9],   # Lymphocytes - blue\n",
    "    'MUC': [0.8, 0.4, 0.8],   # Mucus - purple\n",
    "    'MUS': [0.9, 0.5, 0.3],   # Smooth muscle - orange\n",
    "    'NORM': [0.3, 0.8, 0.3],  # Normal mucosa - green\n",
    "    'STR': [0.6, 0.6, 0.6],   # Stroma - gray\n",
    "    'TUM': [0.9, 0.2, 0.2],   # Tumor - red\n",
    "}\n",
    "\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "for cls_idx, count in zip(unique, counts):\n",
    "    name = class_names[cls_idx]\n",
    "    pct = count / len(predictions) * 100\n",
    "    print(f\"  {name}: {count} patches ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction overlay on the thumbnail\n",
    "slide_w, slide_h = reader.info.slide_dimensions\n",
    "thumb_h, thumb_w = thumbnail.shape[:2]\n",
    "\n",
    "# Create an overlay image\n",
    "overlay = np.ones((thumb_h, thumb_w, 3), dtype=np.float32) * 0.95\n",
    "\n",
    "for pred, coord in zip(predictions, coordinates):\n",
    "    # coord is (x_start, y_start, x_end, y_end) in baseline coords\n",
    "    x1 = int(coord[0] * thumb_w / slide_w)\n",
    "    y1 = int(coord[1] * thumb_h / slide_h)\n",
    "    x2 = int(coord[2] * thumb_w / slide_w)\n",
    "    y2 = int(coord[3] * thumb_h / slide_h)\n",
    "\n",
    "    class_name = class_names[pred]\n",
    "    color = class_colors.get(class_name, [0.5, 0.5, 0.5])\n",
    "    overlay[y1:y2, x1:x2] = color\n",
    "\n",
    "# Blend with thumbnail\n",
    "alpha = 0.5\n",
    "blended = (alpha * overlay + (1 - alpha) * thumbnail / 255.0)\n",
    "blended = np.clip(blended, 0, 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "axes[0].imshow(thumbnail)\n",
    "axes[0].set_title(\"Original Slide\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(blended)\n",
    "axes[1].set_title(\"Tissue Classification Map\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Add legend\n",
    "legend_patches = [\n",
    "    mpatches.Patch(color=color, label=name)\n",
    "    for name, color in class_colors.items()\n",
    "    if name != 'BACK'\n",
    "]\n",
    "axes[1].legend(handles=legend_patches, loc='lower right', fontsize=9,\n",
    "               framealpha=0.9, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examine High-Confidence Predictions\n",
    "\n",
    "Let's look at some example patches for the most common tissue types to verify the classifications look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example patches for select tissue types\n",
    "types_to_show = ['TUM', 'STR', 'LYM', 'NORM']\n",
    "n_examples = 4\n",
    "\n",
    "fig, axes = plt.subplots(len(types_to_show), n_examples, figsize=(4 * n_examples, 4 * len(types_to_show)))\n",
    "\n",
    "for row, tissue_type in enumerate(types_to_show):\n",
    "    type_idx = class_names.index(tissue_type)\n",
    "    matching = [(i, c) for i, (p, c) in enumerate(zip(predictions, coordinates)) if p == type_idx]\n",
    "\n",
    "    # Sample up to n_examples\n",
    "    np.random.seed(42)\n",
    "    if len(matching) > n_examples:\n",
    "        sample_indices = np.random.choice(len(matching), n_examples, replace=False)\n",
    "        matching = [matching[i] for i in sample_indices]\n",
    "\n",
    "    for col in range(n_examples):\n",
    "        ax = axes[row][col]\n",
    "        if col < len(matching):\n",
    "            _, coord = matching[col]\n",
    "            # Read the actual patch at the original resolution\n",
    "            patch = reader.read_bounds(\n",
    "                bounds=coord,\n",
    "                resolution=0.5,\n",
    "                units=\"mpp\"\n",
    "            )\n",
    "            ax.imshow(patch)\n",
    "        ax.axis('off')\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(tissue_type, fontsize=14, rotation=0, labelpad=40)\n",
    "\n",
    "plt.suptitle(\"Example Patches by Predicted Tissue Type\", fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View in SLIM Viewer\n",
    "\n",
    "Compare the computational predictions with the actual slide using IDC's interactive viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_url = idc_client.get_viewer_URL(seriesInstanceUID=series_uid)\n",
    "print(f\"View this slide in SLIM viewer:\")\n",
    "print(viewer_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "\n",
    "- Use `PatchPredictor` with the pretrained `resnet18-kather100k` model for 9-class tissue classification\n",
    "- Run inference in **WSI mode**, which automatically handles patch extraction from tissue regions\n",
    "- Visualize predictions as a color-coded tissue classification map overlaid on the slide\n",
    "- Inspect individual patches to verify classification quality\n",
    "\n",
    "**Available pretrained models** for patch classification include ResNet, DenseNet, MobileNet variants trained on:\n",
    "- **Kather100K**: 9-class colorectal tissue classification\n",
    "- **PCam**: Binary cancer detection in lymph node metastases\n",
    "\n",
    "**Next:** [Notebook 05](05_semantic_segmentation.ipynb) demonstrates pixel-level tissue region segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "- **IDC:** Fedorov, A., et al. \"National Cancer Institute Imaging Data Commons: Toward Transparency, Reproducibility, and Scalability in Imaging Artificial Intelligence.\" *RadioGraphics* 43.12 (2023). https://doi.org/10.1148/rg.230180\n",
    "- **TIAToolbox:** Pocock, J., et al. \"TIAToolbox as an end-to-end library for advanced tissue image analytics.\" *Communications Medicine* 2, 120 (2022). https://doi.org/10.1038/s43856-022-00186-5\n",
    "- **Kather100K:** Kather, J.N., et al. \"Predicting survival from colorectal cancer histology slides using deep learning: A retrospective multicenter study.\" *PLOS Medicine* 16.1 (2019). https://doi.org/10.1371/journal.pmed.1002730"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}