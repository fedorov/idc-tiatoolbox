{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleus Segmentation of IDC Pathology Images with TIAToolbox HoVer-Net\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fedorov/idc-tiatoolbox/blob/main/notebooks/06_nucleus_instance_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Nucleus instance segmentation** detects and classifies individual cell nuclei in tissue images. Unlike semantic segmentation (Notebook 05) which labels pixels, instance segmentation identifies each nucleus as a separate object with its own boundary, type, and properties.\n",
    "\n",
    "This notebook demonstrates TIAToolbox's `NucleusInstanceSegmentor` with the **HoVer-Net** model, which classifies nuclei into 6 types:\n",
    "\n",
    "1. **Neoplastic epithelial** - cancer cells\n",
    "2. **Non-neoplastic epithelial** - normal epithelial cells\n",
    "3. **Inflammatory** - immune cells\n",
    "4. **Connective** - fibroblasts, endothelial cells\n",
    "5. **Dead** - necrotic/apoptotic cells\n",
    "6. **Background** - non-nucleus\n",
    "\n",
    "**GPU required** for reasonable inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Installation\n\nRun the cell below to install dependencies. **On Colab, the runtime will automatically restart** after installation to pick up the updated numpy version. After the restart, continue from the imports cell below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%pip install tiatoolbox idc-index openslide-bin \"numcodecs<0.16\"\n\n# Restart runtime to pick up updated numpy (required on Colab)\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport joblib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport torch\nfrom matplotlib.collections import PatchCollection\nfrom matplotlib.patches import Polygon\n\nfrom idc_index import IDCClient\nfrom tiatoolbox.wsicore.wsireader import WSIReader\nfrom tiatoolbox.models.engine.nucleus_instance_segmentor import NucleusInstanceSegmentor\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nif device == \"cuda\":\n    try:\n        torch.zeros(1, device=\"cuda\")\n    except RuntimeError:\n        print(\"CUDA available but not functional â€” falling back to CPU\")\n        device = \"cpu\"\nprint(f\"Using device: {device}\")\nif device == \"cpu\":\n    print(\"WARNING: GPU is required for reasonable inference time.\")\n    print(\"In Colab: Runtime > Change runtime type > T4 GPU\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Reproducibility Information\n\nCapture execution timestamp and environment details for reproducibility.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import datetime, os, platform, subprocess, sys\nfrom importlib.metadata import version, PackageNotFoundError\n\nprint(f\"Executed: {datetime.datetime.now(datetime.timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\")\nprint(f\"Platform: {platform.platform()}\")\nprint(f\"Python:   {sys.version}\")\n\n# Detect Colab environment and runtime version\ntry:\n    import google.colab  # noqa: F401\n    colab_env = \"Google Colab\"\n    # Try to get the Colab runtime version (e.g., \"2026.01\")\n    colab_release = os.environ.get(\"COLAB_RELEASE_TAG\")\n    if colab_release:\n        colab_env += f\" (runtime {colab_release})\"\n    else:\n        # Fall back to google-colab package version as a proxy\n        try:\n            colab_env += f\" (google-colab {version('google-colab')})\"\n        except PackageNotFoundError:\n            pass\n    print(f\"Runtime:  {colab_env}\")\nexcept ImportError:\n    print(\"Runtime:  Local\")\n\nprint(\"\\nKey package versions:\")\nfor pkg in [\"tiatoolbox\", \"idc-index\", \"numpy\", \"matplotlib\",\n            \"openslide-bin\", \"torch\", \"highdicom\", \"wsidicom\", \"shapely\"]:\n    try:\n        print(f\"  {pkg}: {version(pkg)}\")\n    except PackageNotFoundError:\n        pass\n\ntry:\n    import psutil\n    ram = psutil.virtual_memory()\n    print(f\"\\nRAM: {ram.total / (1024**3):.1f} GB total, {ram.available / (1024**3):.1f} GB available\")\nexcept ImportError:\n    pass\n\ntry:\n    result = subprocess.run(\n        [\"nvidia-smi\", \"--query-gpu=name,memory.total,driver_version\", \"--format=csv,noheader\"],\n        capture_output=True, text=True, timeout=5,\n    )\n    if result.returncode == 0:\n        print(f\"GPU:  {result.stdout.strip()}\")\n    else:\n        print(\"GPU:  Not available\")\nexcept (FileNotFoundError, subprocess.TimeoutExpired):\n    print(\"GPU:  Not available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select and Download a Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "idc_client = IDCClient()\nidc_client.fetch_index(\"sm_index\")\n\n# Select a breast cancer slide (TCGA-BRCA)\ncandidates = idc_client.sql_query(\"\"\"\n    SELECT\n        i.SeriesInstanceUID,\n        i.PatientID,\n        ROUND(i.series_size_MB, 1) as size_mb,\n        s.ObjectiveLensPower,\n        s.max_TotalPixelMatrixColumns as width,\n        s.max_TotalPixelMatrixRows as height,\n        s.min_PixelSpacing_2sf as pixel_spacing_mm\n    FROM sm_index s\n    JOIN index i ON s.SeriesInstanceUID = i.SeriesInstanceUID\n    WHERE i.collection_id = 'tcga_brca'\n        AND s.ObjectiveLensPower >= 20\n    ORDER BY i.series_size_MB ASC\n    LIMIT 5\n\"\"\")\n\nselected = candidates.iloc[0]\nseries_uid = selected['SeriesInstanceUID']\nprint(f\"Selected: {selected['PatientID']}, {selected['size_mb']} MB\")\nprint(f\"  Dimensions: {selected['width']}x{selected['height']} @ {selected['ObjectiveLensPower']}x\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "download_dir = './slides'\nos.makedirs(download_dir, exist_ok=True)\n\nidc_client.download_from_selection(\n    downloadDir=download_dir,\n    seriesInstanceUID=[series_uid],\n    dirTemplate='%SeriesInstanceUID'\n)\n\nslide_path = os.path.join(download_dir, series_uid)\nreader = WSIReader.open(slide_path)\n\n# DICOMWSIReader may not populate objective_power or mpp\ninfo = reader.info\nif info.objective_power is None:\n    info.objective_power = float(selected['ObjectiveLensPower'])\nif info.mpp is None:\n    pixel_spacing_um = float(selected['pixel_spacing_mm']) * 1000\n    info.mpp = np.array([pixel_spacing_um, pixel_spacing_um])\n\nprint(f\"Opened: {type(reader).__name__}, dimensions: {info.slide_dimensions}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract a Tissue Tile\n",
    "\n",
    "HoVer-Net works at high resolution (0.25 mpp, ~40x). For this demo, we'll extract a single tile to keep inference time manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find tissue region\nthumbnail = reader.slide_thumbnail(resolution=1.25, units=\"power\")\ngray = np.mean(thumbnail, axis=2)\ntissue_mask = gray < 200\ntissue_coords = np.argwhere(tissue_mask)\n\ncenter_y, center_x = tissue_coords.mean(axis=0).astype(int)\nslide_w, slide_h = info.slide_dimensions\n\nbaseline_x = int(center_x * slide_w / thumbnail.shape[1])\nbaseline_y = int(center_y * slide_h / thumbnail.shape[0])\n\n# Extract a 2048x2048 tile in baseline coordinates\n# DICOMWSIReader has coordinate issues at non-native resolutions,\n# so we read at native resolution and resize if needed.\ntile_size = 2048\nbaseline_mpp = float(info.mpp[0])\ntarget_mpp = 0.5\n\nbaseline_extent = int(tile_size * target_mpp / baseline_mpp)\n\nbounds = (\n    max(0, baseline_x - baseline_extent // 2),\n    max(0, baseline_y - baseline_extent // 2),\n    min(slide_w, baseline_x + baseline_extent // 2),\n    min(slide_h, baseline_y + baseline_extent // 2),\n)\n\ntile = reader.read_bounds(\n    bounds=bounds,\n    resolution=info.objective_power,\n    units=\"power\",\n)\n\n# Resize to target tile size if native mpp differs from target\nfrom PIL import Image\nif tile.shape[0] != tile_size or tile.shape[1] != tile_size:\n    tile = np.array(Image.fromarray(tile).resize((tile_size, tile_size), Image.LANCZOS))\n\nprint(f\"Tile shape: {tile.shape}\")\n\nplt.figure(figsize=(8, 8))\nplt.imshow(tile)\nplt.title(f\"Tissue Tile ({tile_size}x{tile_size} @ ~{target_mpp} mpp)\", fontsize=14)\nplt.axis('off')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tile for the segmentor\n",
    "from PIL import Image\n",
    "tile_path = './tile_for_nucleus_seg.png'\n",
    "Image.fromarray(tile).save(tile_path)\n",
    "print(f\"Tile saved to {tile_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run HoVer-Net Nucleus Instance Segmentation\n",
    "\n",
    "**HoVer-Net** uses horizontal and vertical distance maps to separate touching/overlapping nuclei. The `hovernet_fast-pannuke` variant was trained on the [PanNuke](https://warwick.ac.uk/fac/cross_fac/tia/data/pannuke/) dataset, which includes tissue from 19 different organs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor = NucleusInstanceSegmentor(\n",
    "    pretrained_model=\"hovernet_fast-pannuke\",\n",
    "    num_loader_workers=0,\n",
    "    num_postproc_workers=0,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "print(\"HoVer-Net (PanNuke) loaded.\")\n",
    "print(\"Nucleus types: 0=Background, 1=Neoplastic, 2=Non-neoplastic epithelial, 3=Inflammatory, 4=Connective, 5=Dead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run inference\noutput = segmentor.predict(\n    imgs=[tile_path],\n    mode=\"tile\",\n    save_dir=\"./nuc_seg_results/\",\n    resolution=1.0,\n    units=\"baseline\",\n    device=device,\n)\n\nprint(\"Nucleus segmentation complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Explore Results\n",
    "\n",
    "HoVer-Net results are saved as `.dat` files (Python dictionaries serialized with joblib). Each entry contains:\n",
    "- `box`: Bounding box [x, y, width, height]\n",
    "- `centroid`: Center point [x, y]\n",
    "- `contour`: Boundary polygon\n",
    "- `prob`: Classification confidence\n",
    "- `type`: Nucleus type (1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "result_path = output[0][1] + '.dat'\n",
    "nuclei = joblib.load(result_path)\n",
    "\n",
    "print(f\"Total nuclei detected: {len(nuclei)}\")\n",
    "\n",
    "# Show structure of first nucleus\n",
    "if len(nuclei) > 0:\n",
    "    first_key = list(nuclei.keys())[0]\n",
    "    print(f\"\\nExample nucleus (key={first_key}):\")\n",
    "    for k, v in nuclei[first_key].items():\n",
    "        if k == 'contour':\n",
    "            print(f\"  {k}: array with {len(v)} points\")\n",
    "        else:\n",
    "            print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by nucleus type\n",
    "type_names = {\n",
    "    0: 'Background',\n",
    "    1: 'Neoplastic',\n",
    "    2: 'Non-neoplastic epithelial',\n",
    "    3: 'Inflammatory',\n",
    "    4: 'Connective',\n",
    "    5: 'Dead',\n",
    "}\n",
    "\n",
    "type_counts = {}\n",
    "for nuc in nuclei.values():\n",
    "    t = nuc['type']\n",
    "    type_counts[t] = type_counts.get(t, 0) + 1\n",
    "\n",
    "print(\"Nucleus type distribution:\")\n",
    "print(\"-\" * 45)\n",
    "for t in sorted(type_counts.keys()):\n",
    "    name = type_names.get(t, f'Type {t}')\n",
    "    count = type_counts[t]\n",
    "    pct = count / len(nuclei) * 100\n",
    "    print(f\"  {name:30s}: {count:5d} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Nucleus Contours\n",
    "\n",
    "Let's overlay the detected nucleus contours on the tissue tile, color-coded by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for each nucleus type\n",
    "type_colors = {\n",
    "    1: [0.9, 0.2, 0.2],   # Neoplastic - red\n",
    "    2: [0.2, 0.8, 0.2],   # Non-neoplastic epithelial - green\n",
    "    3: [0.2, 0.5, 0.9],   # Inflammatory - blue\n",
    "    4: [0.9, 0.7, 0.1],   # Connective - yellow\n",
    "    5: [0.1, 0.1, 0.1],   # Dead - black\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(tile)\n",
    "\n",
    "for nuc in nuclei.values():\n",
    "    nuc_type = nuc['type']\n",
    "    if nuc_type == 0:\n",
    "        continue  # Skip background\n",
    "    contour = nuc['contour']\n",
    "    color = type_colors.get(nuc_type, [0.5, 0.5, 0.5])\n",
    "    polygon = Polygon(contour, closed=True, fill=True,\n",
    "                      facecolor=(*color, 0.3), edgecolor=(*color, 0.8),\n",
    "                      linewidth=0.5)\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "# Add legend\n",
    "legend_patches = [\n",
    "    mpatches.Patch(color=color, label=type_names[t])\n",
    "    for t, color in type_colors.items()\n",
    "]\n",
    "ax.legend(handles=legend_patches, loc='upper right', fontsize=10, framealpha=0.9)\n",
    "\n",
    "ax.set_title(f\"Nucleus Instance Segmentation ({len(nuclei)} nuclei detected)\", fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoomed-In View\n",
    "\n",
    "Let's zoom into a smaller region to see individual nuclei more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into a 512x512 region\n",
    "zoom_x, zoom_y = tile_size // 4, tile_size // 4\n",
    "zoom_size = 512\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Original zoomed\n",
    "zoomed_tile = tile[zoom_y:zoom_y+zoom_size, zoom_x:zoom_x+zoom_size]\n",
    "axes[0].imshow(zoomed_tile)\n",
    "axes[0].set_title(\"Zoomed Region (Original)\", fontsize=13)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# With nucleus overlays\n",
    "axes[1].imshow(zoomed_tile)\n",
    "\n",
    "for nuc in nuclei.values():\n",
    "    nuc_type = nuc['type']\n",
    "    if nuc_type == 0:\n",
    "        continue\n",
    "    centroid = nuc['centroid']\n",
    "    # Check if nucleus is in the zoomed region\n",
    "    if (zoom_x <= centroid[0] < zoom_x + zoom_size and\n",
    "        zoom_y <= centroid[1] < zoom_y + zoom_size):\n",
    "        contour = nuc['contour'] - np.array([zoom_x, zoom_y])\n",
    "        color = type_colors.get(nuc_type, [0.5, 0.5, 0.5])\n",
    "        polygon = Polygon(contour, closed=True, fill=True,\n",
    "                          facecolor=(*color, 0.4), edgecolor=(*color, 1.0),\n",
    "                          linewidth=1)\n",
    "        axes[1].add_patch(polygon)\n",
    "\n",
    "legend_patches = [\n",
    "    mpatches.Patch(color=color, label=type_names[t])\n",
    "    for t, color in type_colors.items()\n",
    "]\n",
    "axes[1].legend(handles=legend_patches, loc='upper right', fontsize=9, framealpha=0.9)\n",
    "axes[1].set_title(\"Zoomed Region (with Nuclei)\", fontsize=13)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Nuclear Morphometry Statistics\n",
    "\n",
    "The per-nucleus data allows us to compute morphometric features like nucleus area, aspect ratio, and spatial density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon as ShapelyPolygon\n",
    "\n",
    "# Compute areas for each nucleus\n",
    "areas_by_type = {t: [] for t in type_colors.keys()}\n",
    "\n",
    "for nuc in nuclei.values():\n",
    "    nuc_type = nuc['type']\n",
    "    if nuc_type == 0:\n",
    "        continue\n",
    "    contour = nuc['contour']\n",
    "    if len(contour) >= 3:\n",
    "        poly = ShapelyPolygon(contour)\n",
    "        if poly.is_valid:\n",
    "            areas_by_type[nuc_type].append(poly.area)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Nuclear area statistics (pixels^2):\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Type':30s}  {'Count':>6s}  {'Mean':>8s}  {'Std':>8s}\")\n",
    "print(\"-\" * 55)\n",
    "for t in sorted(areas_by_type.keys()):\n",
    "    areas = areas_by_type[t]\n",
    "    if len(areas) > 0:\n",
    "        name = type_names[t]\n",
    "        print(f\"  {name:28s}  {len(areas):6d}  {np.mean(areas):8.1f}  {np.std(areas):8.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot area distributions by type\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "for t in sorted(areas_by_type.keys()):\n",
    "    areas = areas_by_type[t]\n",
    "    if len(areas) > 10:\n",
    "        color = type_colors[t]\n",
    "        ax.hist(areas, bins=50, alpha=0.5, color=color,\n",
    "                label=f\"{type_names[t]} (n={len(areas)})\", density=True)\n",
    "\n",
    "ax.set_xlabel(\"Nucleus Area (pixels^2)\", fontsize=12)\n",
    "ax.set_ylabel(\"Density\", fontsize=12)\n",
    "ax.set_title(\"Nuclear Area Distribution by Type\", fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_xlim(0, np.percentile([a for areas in areas_by_type.values() for a in areas], 95))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "\n",
    "- Use `NucleusInstanceSegmentor` with the pretrained `hovernet_fast-pannuke` model\n",
    "- Run nucleus detection on a tile extracted from an IDC slide\n",
    "- Load and explore per-nucleus results (bounding boxes, centroids, contours, types, probabilities)\n",
    "- Visualize nucleus contours color-coded by type (neoplastic, inflammatory, connective, etc.)\n",
    "- Compute nuclear morphometry statistics (area distributions)\n",
    "\n",
    "**Next:** [Notebook 07](07_comparing_with_idc_annotations.ipynb) compares TIAToolbox HoVer-Net results with IDC's Pan-Cancer-Nuclei-Seg-DICOM annotations for quantitative validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "- **IDC:** Fedorov, A., et al. \"National Cancer Institute Imaging Data Commons: Toward Transparency, Reproducibility, and Scalability in Imaging Artificial Intelligence.\" *RadioGraphics* 43.12 (2023). https://doi.org/10.1148/rg.230180\n",
    "- **TIAToolbox:** Pocock, J., et al. \"TIAToolbox as an end-to-end library for advanced tissue image analytics.\" *Communications Medicine* 2, 120 (2022). https://doi.org/10.1038/s43856-022-00186-5\n",
    "- **HoVer-Net:** Graham, S., et al. \"Hover-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images.\" *Medical Image Analysis* 58 (2019). https://doi.org/10.1016/j.media.2019.101563\n",
    "- **PanNuke:** Gamper, J., et al. \"PanNuke Dataset Extension, Insights and Baselines.\" arXiv:2003.10778 (2020). https://doi.org/10.48550/arXiv.2003.10778"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}