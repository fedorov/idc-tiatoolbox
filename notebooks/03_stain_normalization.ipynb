{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stain Normalization of IDC Pathology Images with TIAToolbox\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fedorov/idc-tiatoolbox/blob/main/notebooks/03_stain_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "H&E (Hematoxylin and Eosin) stained slides from different laboratories, scanners, or staining protocols can have significantly different color appearances. This color variation can confuse computational pathology algorithms that were trained on data with a particular staining style.\n",
    "\n",
    "**Stain normalization** transforms the color appearance of a source image to match a target image, reducing batch effects while preserving tissue structure.\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Download slides from two different IDC collections to show staining variation\n",
    "- Apply three normalization methods: **Macenko**, **Reinhard**, and **Vahadane**\n",
    "- Compare the results side-by-side\n",
    "\n",
    "**No GPU required** for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Installation\n\nRun the cell below to install dependencies. **On Colab, the runtime will automatically restart** after installation to pick up the updated numpy version. After the restart, continue from the imports cell below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%pip install tiatoolbox idc-index openslide-bin \"numcodecs<0.16\"\n\n# Restart runtime to pick up updated numpy (required on Colab)\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from idc_index import IDCClient\n",
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "from tiatoolbox.tools.stainnorm import (\n",
    "    MacenkoNormalizer,\n",
    "    ReinhardNormalizer,\n",
    "    VahadaneNormalizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select Slides from Two Different Collections\n",
    "\n",
    "To demonstrate stain variation, we'll select slides from two different collections that image the same tissue type (lung) but were scanned at different sites with potentially different staining protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idc_client = IDCClient()\n",
    "idc_client.fetch_index(\"sm_index\")\n",
    "\n",
    "# Find small 20x slides from two different lung cancer collections\n",
    "collections = ['cptac_luad', 'tcga_luad']\n",
    "slides = {}\n",
    "\n",
    "for collection in collections:\n",
    "    result = idc_client.sql_query(f\"\"\"\n",
    "        SELECT\n",
    "            i.SeriesInstanceUID,\n",
    "            i.PatientID,\n",
    "            i.collection_id,\n",
    "            ROUND(i.series_size_MB, 1) as size_mb,\n",
    "            s.ObjectiveLensPower\n",
    "        FROM sm_index s\n",
    "        JOIN index i ON s.SeriesInstanceUID = i.SeriesInstanceUID\n",
    "        WHERE i.collection_id = '{collection}'\n",
    "            AND s.ObjectiveLensPower >= 20\n",
    "        ORDER BY i.series_size_MB ASC\n",
    "        LIMIT 1\n",
    "    \"\"\")\n",
    "    slides[collection] = result.iloc[0]\n",
    "    print(f\"{collection}: {result.iloc[0]['PatientID']}, {result.iloc[0]['size_mb']} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download both slides\n",
    "download_dir = './slides'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "readers = {}\n",
    "for collection, info in slides.items():\n",
    "    series_uid = info['SeriesInstanceUID']\n",
    "    idc_client.download_from_selection(\n",
    "        downloadDir=download_dir,\n",
    "        seriesInstanceUID=[series_uid],\n",
    "        dirTemplate='%SeriesInstanceUID'\n",
    "    )\n",
    "    slide_path = os.path.join(download_dir, series_uid)\n",
    "    readers[collection] = WSIReader.open(slide_path)\n",
    "    print(f\"Opened {collection}: {type(readers[collection]).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Tissue Patches and Observe Stain Variation\n",
    "\n",
    "Let's extract patches from tissue-rich areas of both slides and compare their color appearance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tissue_patch(reader, patch_size=512, resolution=10, units=\"power\"):\n",
    "    \"\"\"Find a tissue-rich patch from the slide.\"\"\"\n",
    "    # Get thumbnail and find tissue\n",
    "    thumb = reader.slide_thumbnail(resolution=1.25, units=\"power\")\n",
    "    gray = np.mean(thumb, axis=2)\n",
    "    tissue_mask = gray < 200\n",
    "\n",
    "    # Find tissue center\n",
    "    coords = np.argwhere(tissue_mask)\n",
    "    if len(coords) == 0:\n",
    "        center_y, center_x = thumb.shape[0] // 2, thumb.shape[1] // 2\n",
    "    else:\n",
    "        center_y, center_x = coords.mean(axis=0).astype(int)\n",
    "\n",
    "    # Scale to target resolution\n",
    "    slide_w, slide_h = reader.info.slide_dimensions\n",
    "    baseline_x = int(center_x * slide_w / thumb.shape[1])\n",
    "    baseline_y = int(center_y * slide_h / thumb.shape[0])\n",
    "\n",
    "    scale = resolution / reader.info.objective_power\n",
    "    location = (int(baseline_x * scale), int(baseline_y * scale))\n",
    "\n",
    "    patch = reader.read_rect(\n",
    "        location=location,\n",
    "        size=(patch_size, patch_size),\n",
    "        resolution=resolution,\n",
    "        units=units\n",
    "    )\n",
    "    return patch\n",
    "\n",
    "\n",
    "# Extract patches from both slides\n",
    "patch_target = find_tissue_patch(readers['cptac_luad'])\n",
    "patch_source = find_tissue_patch(readers['tcga_luad'])\n",
    "\n",
    "# Show side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].imshow(patch_target)\n",
    "axes[0].set_title(\"CPTAC-LUAD (Target)\", fontsize=13)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(patch_source)\n",
    "axes[1].set_title(\"TCGA-LUAD (Source)\", fontsize=13)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Stain variation between collections\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Stain Normalization Methods\n",
    "\n",
    "TIAToolbox provides three stain normalization methods:\n",
    "\n",
    "- **Reinhard**: Simple color transfer in LAB color space. Fast but may not preserve structure well.\n",
    "- **Macenko**: Decomposes stain vectors using SVD. Better structure preservation.\n",
    "- **Vahadane**: Sparse non-negative matrix factorization for stain separation. Best structure preservation but slowest.\n",
    "\n",
    "The workflow is:\n",
    "1. **Fit** the normalizer to a target image (the desired color appearance)\n",
    "2. **Transform** the source image(s) to match the target's staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizers = {\n",
    "    \"Reinhard\": ReinhardNormalizer(),\n",
    "    \"Macenko\": MacenkoNormalizer(),\n",
    "    \"Vahadane\": VahadaneNormalizer(),\n",
    "}\n",
    "\n",
    "# Fit each normalizer to the target patch\n",
    "for name, normalizer in normalizers.items():\n",
    "    normalizer.fit(patch_target)\n",
    "    print(f\"{name} normalizer fitted to target.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the source patch with each method\n",
    "normalized = {}\n",
    "for name, normalizer in normalizers.items():\n",
    "    normalized[name] = normalizer.transform(patch_source.copy())\n",
    "    print(f\"{name} normalization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all results\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "axes[0].imshow(patch_target)\n",
    "axes[0].set_title(\"Target\\n(CPTAC-LUAD)\", fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(patch_source)\n",
    "axes[1].set_title(\"Source\\n(TCGA-LUAD, original)\", fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "for i, (name, result) in enumerate(normalized.items()):\n",
    "    axes[i + 2].imshow(result)\n",
    "    axes[i + 2].set_title(f\"Source normalized\\n({name})\", fontsize=12)\n",
    "    axes[i + 2].axis('off')\n",
    "\n",
    "plt.suptitle(\"Stain Normalization Comparison\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalize Multiple Patches\n",
    "\n",
    "Let's extract several patches from the source slide and normalize them all to show that the method works consistently across different tissue regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract multiple patches at different positions\n",
    "source_reader = readers['tcga_luad']\n",
    "thumb = source_reader.slide_thumbnail(resolution=1.25, units=\"power\")\n",
    "gray = np.mean(thumb, axis=2)\n",
    "tissue_mask = gray < 200\n",
    "tissue_coords = np.argwhere(tissue_mask)\n",
    "\n",
    "slide_w, slide_h = source_reader.info.slide_dimensions\n",
    "\n",
    "# Sample 4 random tissue locations\n",
    "np.random.seed(42)\n",
    "n_patches = 4\n",
    "sample_indices = np.random.choice(len(tissue_coords), n_patches, replace=False)\n",
    "\n",
    "source_patches = []\n",
    "for idx in sample_indices:\n",
    "    ty, tx = tissue_coords[idx]\n",
    "    bx = int(tx * slide_w / thumb.shape[1])\n",
    "    by = int(ty * slide_h / thumb.shape[0])\n",
    "    scale = 10 / source_reader.info.objective_power\n",
    "    loc = (int(bx * scale), int(by * scale))\n",
    "    patch = source_reader.read_rect(location=loc, size=(256, 256), resolution=10, units=\"power\")\n",
    "    source_patches.append(patch)\n",
    "\n",
    "# Normalize with Macenko\n",
    "macenko = MacenkoNormalizer()\n",
    "macenko.fit(patch_target)\n",
    "\n",
    "fig, axes = plt.subplots(2, n_patches, figsize=(4 * n_patches, 8))\n",
    "for i, patch in enumerate(source_patches):\n",
    "    axes[0][i].imshow(patch)\n",
    "    axes[0][i].set_title(f\"Original {i+1}\", fontsize=11)\n",
    "    axes[0][i].axis('off')\n",
    "\n",
    "    norm_patch = macenko.transform(patch.copy())\n",
    "    axes[1][i].imshow(norm_patch)\n",
    "    axes[1][i].set_title(f\"Macenko normalized {i+1}\", fontsize=11)\n",
    "    axes[1][i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Macenko Normalization of Multiple Patches\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Color Distribution Comparison\n",
    "\n",
    "Let's visualize how normalization shifts the color distributions of the source to match the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "colors = ['red', 'green', 'blue']\n",
    "channel_names = ['Red', 'Green', 'Blue']\n",
    "\n",
    "for i, (color, name) in enumerate(zip(colors, channel_names)):\n",
    "    axes[i].hist(patch_target[:, :, i].ravel(), bins=50, alpha=0.5,\n",
    "                 color=color, label='Target', density=True)\n",
    "    axes[i].hist(patch_source[:, :, i].ravel(), bins=50, alpha=0.5,\n",
    "                 color='gray', label='Source (original)', density=True, linestyle='--')\n",
    "    axes[i].hist(normalized['Macenko'][:, :, i].ravel(), bins=50, alpha=0.5,\n",
    "                 color='black', label='Source (Macenko)', density=True)\n",
    "    axes[i].set_title(f\"{name} Channel\", fontsize=12)\n",
    "    axes[i].legend(fontsize=9)\n",
    "    axes[i].set_xlabel(\"Pixel Intensity\")\n",
    "    axes[i].set_ylabel(\"Density\")\n",
    "\n",
    "plt.suptitle(\"Color Distribution: Target vs Source vs Normalized\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "\n",
    "- Identify **stain variation** between slides from different IDC collections/scanners\n",
    "- Apply three TIAToolbox normalization methods: **Reinhard**, **Macenko**, and **Vahadane**\n",
    "- **Fit** a normalizer to a target image and **transform** source images to match\n",
    "- Compare normalization results both visually and through color distributions\n",
    "\n",
    "**When to use which method:**\n",
    "- **Reinhard**: Fastest, good for quick preprocessing when speed matters\n",
    "- **Macenko**: Good balance of speed and quality, widely used in practice\n",
    "- **Vahadane**: Best structure preservation, recommended when quality is critical\n",
    "\n",
    "**Next:** [Notebook 04](04_patch_classification.ipynb) demonstrates tissue patch classification using TIAToolbox's pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "- **IDC:** Fedorov, A., et al. \"National Cancer Institute Imaging Data Commons: Toward Transparency, Reproducibility, and Scalability in Imaging Artificial Intelligence.\" *RadioGraphics* 43.12 (2023). https://doi.org/10.1148/rg.230180\n",
    "- **TIAToolbox:** Pocock, J., et al. \"TIAToolbox as an end-to-end library for advanced tissue image analytics.\" *Communications Medicine* 2, 120 (2022). https://doi.org/10.1038/s43856-022-00186-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}